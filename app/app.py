import streamlit as st
import pandas as pd
import numpy as np
import joblib
import shap
import matplotlib.pyplot as plt
from io import BytesIO
from fpdf import FPDF
from datetime import datetime

# Load model
model = joblib.load("../models/xgboost_model.pkl")

# Load background dataset for SHAP
df = pd.read_csv("../output/cleaned_multi_class_url_dataset.csv")
X = df.drop(columns=["Label", "URL_Type_obf_Type"])

explainer = shap.TreeExplainer(model)

# Label mapping
numeric_to_text = {
    0: "benign",
    1: "phishing",
    2: "spam",
    3: "malware",
    4: "defacement"
}

# Page config
st.set_page_config(page_title="Phishing URL Classifier", layout="wide")

# Sidebar with logo
st.sidebar.image("assets/log.png", width=180)
st.sidebar.title("Navigation")
page = st.sidebar.radio("Go to", ["üè† Home", "üìà Predict & Explain", "üìÑ Download Report"])

# Home Page
if page == "üè† Home":
    st.title("Phishing Website Detection App")
    st.markdown("""
    This web application allows you to:
    - Upload URL feature data
    - Predict whether a URL is phishing, malware, spam, defacement, or benign
    - See SHAP interpretability plots
    - Download a professional PDF report
    """)

# Predict & Explain
if page == "üìà Predict & Explain":
    st.title("Predict URL Type")
    st.write("Upload a CSV file with the **same 79 numeric features used for training.**")

    uploaded_file = st.file_uploader("Choose a CSV file", type="csv")

    if uploaded_file is not None:
        input_df = pd.read_csv(uploaded_file)

        preds = model.predict(input_df)
        probas = model.predict_proba(input_df)

        class_labels = model.classes_
        text_labels = [numeric_to_text[c] for c in class_labels]

        # Store predictions
        st.session_state['predictions'] = []

        for i in range(len(preds)):
            st.subheader(f"Sample {i+1}")
            st.write(f"**Predicted Class:** {numeric_to_text[preds[i]]}")
            proba_df = pd.DataFrame(
                {"Probability": probas[i]},
                index=text_labels
            )
            st.dataframe(proba_df)

            # Save to session state
            st.session_state['predictions'].append({
                "sample": i+1,
                "predicted_class": numeric_to_text[preds[i]],
                "probabilities": dict(zip(text_labels, probas[i].round(3).tolist()))
            })

            # SHAP Explanation
            shap_values = explainer(input_df.iloc[[i]])

            # Get predicted class index
            pred_class_index = preds[i]

            # Slice the SHAP values to get a single explanation vector
            values_for_class = shap_values.values[0, :, pred_class_index]
            base_value_for_class = shap_values.base_values[0][pred_class_index]

            # Build Explanation object
            explanation = shap.Explanation(
                values=values_for_class,
                base_values=base_value_for_class,
                data=input_df.iloc[i],
                feature_names=X.columns.tolist()
            )

            # Create waterfall plot
            fig, ax = plt.subplots(figsize=(6, 6))
            shap.plots.waterfall(explanation, max_display=15, show=False)
            st.pyplot(fig)

# Download Report
if page == "üìÑ Download Report":
    st.title("Download Prediction Report")

    if 'predictions' not in st.session_state or len(st.session_state['predictions']) == 0:
        st.warning("No predictions available. Please run predictions first.")
    else:
        if st.button("Generate PDF Report"):
            pdf = FPDF()
            pdf.add_page()

            # Logo
            pdf.image("assets/log.png", x=80, w=50)

            # Title
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "Phishing Detection Report", ln=True, align="C")
            pdf.ln(5)

            pdf.set_font("Arial", "I", 10)
            pdf.cell(0, 8, f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", ln=True, align="C")
            pdf.ln(5)

            pdf.set_font("Arial", size=12)
            pdf.multi_cell(0, 8, "This report contains prediction details generated by the Phishing URL Classifier.\n")

            # Add each prediction
            for record in st.session_state['predictions']:
                pdf.set_font("Arial", "B", 12)
                pdf.cell(0, 8, f"Sample {record['sample']}: {record['predicted_class'].upper()}", ln=True)
                pdf.set_font("Arial", size=11)
                for label, prob in record["probabilities"].items():
                    pdf.cell(0, 6, f"- {label}: {prob}", ln=True)
                pdf.ln(4)

            pdf.ln(5)
            pdf.set_font("Arial", "I", 10)
            pdf.cell(0, 8, "This document was auto-generated by the Explainable AI Phishing Detector.", ln=True, align="C")

            pdf_bytes = pdf.output(dest="S").encode("latin1")

            st.download_button(
                label="Download Report PDF",
                data=pdf_bytes,
                file_name="phishing_report.pdf",
                mime="application/pdf"
            )
